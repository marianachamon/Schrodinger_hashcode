{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "from random import random as rnd\n",
    "from random import gauss, randrange\n",
    "import random\n",
    "from datetime import datetime\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./me_at_the_zoo.in\"\n",
    "path = \"./videos_worth_spreading.in\"\n",
    "#path = \"./trending_today.in\"\n",
    "#path = \"./kittens.in.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_latency(a):\n",
    "    difference_to_endpoints = {}\n",
    "    endpoints_to_video = list_endpoints[a[0]]\n",
    "    for endpoint in endpoints_to_video:\n",
    "        difference_to_endpoints[endpoint] = request_dict[(endpoint, a[0])]*(a[2] if (endpoint,a[1]) in latency else 0)\n",
    "    for c in lat_gain[a[0]]:\n",
    "            reduction_in_lat_gain = sum([difference_to_endpoints[endpoint] for endpoint in endpoints_to_video if (endpoint, c) in latency])\n",
    "            lat_gain[a[0]][c] = (lat_gain[a[0]][c]*sizes_videos[a[0]]-reduction_in_lat_gain)/sizes_videos[a[0]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path) as f:\n",
    "    V, E, R, C, X = [int(x) for x in next(f).split()]\n",
    "    sizes_videos = [int(x) for x in next(f).split()]\n",
    "    endpoints = []\n",
    "    for i in range(E):\n",
    "        datacen_lat, num_caches = [int(x) for x in next(f).split()]\n",
    "        connection = []\n",
    "        for j in range(num_caches):\n",
    "            ep_lat = [int(x) for x in next(f).split()]\n",
    "            connection.append(ep_lat)\n",
    "        endpoints.append([datacen_lat, num_caches, connection])\n",
    "    requests = []\n",
    "    for i in range(R):\n",
    "        requests.append([int(x) for x in next(f).split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a latency map\n",
    "\n",
    "latency = {}\n",
    "# (endpoint, cache) -> latency\n",
    "for i in range(E):\n",
    "    latency[(i,-1)] = endpoints[i][0]\n",
    "    for j in range(endpoints[i][1]):\n",
    "        latency[(i,endpoints[i][2][j][0])] = endpoints[i][2][j][1]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_dict = {}\n",
    "# (endpoint, video) -> num_request\n",
    "for i in range(R):\n",
    "    request_dict[(requests[i][1], requests[i][0])] = requests[i][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video -> list of endpoints requesting it\n",
    "list_endpoints = {}\n",
    "for i in range(V):\n",
    "    list_endpoints[i] = []\n",
    "for i in range(R):\n",
    "    list_endpoints[requests[i][0]].append(requests[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map for latency gain\n",
    "lat_gain = {}\n",
    "# (video)-> (cache) -> if added then what is gained latency at the moment\n",
    "for v in range(V):\n",
    "    lat_gain[v] = {}\n",
    "    for c in range(C):\n",
    "        original_latency = sum([(latency[(list_endpoints[v][x],-1)])*request_dict[(list_endpoints[v][x],v)] for x in range(len(list_endpoints[v]))])\n",
    "        #latency[(2,0)]\n",
    "        reduced_latency = sum([(latency[(list_endpoints[v][x], c)])*request_dict[(list_endpoints[v][x],v)] for x in range(len(list_endpoints[v])) if (list_endpoints[v][x],c) in latency])\n",
    "        lat_gain[v][c] = (original_latency - reduced_latency)/sizes_videos[v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "max_lat_list = []\n",
    "for v in range(V):\n",
    "    #tuple (v, cache, lat_gain_value)\n",
    "    max_lat_list.append((v, max(lat_gain[v].items(), key=operator.itemgetter(1))[0], max(lat_gain[v].items(), key=operator.itemgetter(1))[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_availability = [X for i in range(C)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = [[] for i in range(C)]\n",
    "for i in range(V*C):\n",
    "    a = max(max_lat_list, key = operator.itemgetter(2))\n",
    "    if sizes_videos[a[0]] <= size_availability[a[1]]:\n",
    "        #final_result.append((a[1], a[0]))\n",
    "        final_result[a[1]].append(a[0])\n",
    "        size_availability[a[1]] = size_availability[a[1]] - sizes_videos[a[0]]\n",
    "        del lat_gain[a[0]][a[1]]\n",
    "        update_latency(a)\n",
    "        max_lat_list[a[0]] = (a[0], max(lat_gain[a[0]].items(), key=operator.itemgetter(1))[0], max(lat_gain[a[0]].items(), key=operator.itemgetter(1))[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individualc=final_result\n",
    "fitness_value = 0    \n",
    "for i in range(0,len(requests)):  \n",
    "    #req[i,1]: index of the endPoint in req i\n",
    "    cachesEndp = endpoints[requests[i][1]][2]# Get caches connect to endPoint of req i\n",
    "    lci = 0\n",
    "    Ldi=0\n",
    "    for ci,lc in cachesEndp:\n",
    "        if  requests[i][0] in individualc[ci]: # if the video from req i is in one or more of the caches\n",
    "            aux = lc # get lattency of cache_x-endPoint_i\n",
    "            if aux < lci  or lci==0:\n",
    "                lci = aux\n",
    "                Ldi = endpoints[requests[i][1]][ 0 ] \n",
    "    fitness_value += (Ldi - lci)*requests[i][2]\n",
    "fitness_value *= 1000/np.sum([x[2] for x in requests])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
